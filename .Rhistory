class(table4a_copy)
setDT(table4a_copy)
require(data.table)
setDT(table4a_copy)
table4a.head()
table4a.head()
colnames(table4b_copy)
table4b_copy <- table4b
setDT(table4b_copy)
colnames(table4b_copy)
table4b_copy <-
melt(table4b_copy,
id.vars = "country",
variable.name = "year",
value.name = "populations")
table4b
table4b_copy
colnames(table4a)
columns(table1)
column(table1)
## working with tidy data
options(scipen = 999)
table1 %>%
mutate(rate = cases / population * 10000)
table1 %>%
count(year, wt = cases)
column(table1)
library(nycflights13)
data(flights)
data(airlines)
flights2 <- flights %>%
select(year:day, hour, origin, dest, tailnum, carrier)
View(flights)
View(flights2)
head(airlines)
flights2 <- flights %>%
select(year:day, hour, origin, dest, tailnum, carrier)
flights2 %>%
inner_join(airlines, by = "carrier")
View(airlines)
joined_table <- airlines %>%
inner_join(flights2, by = "carrier")
joined_table
View(flights2)
data(airports); View(airports)
View(flights2)
data(airports); View(airports)
View(flights2)
data(airports); View(airports)
View(flights2)
data(airports); View(airports)
left_join(flights, airports, by = c("origin" = "faa"))
left_join(flights, airports, by = c("origin" = "faa"))
left_joined_table <- left_join(flights, airports, by = c("origin" = "faa"))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
list.of.packages <- c("plotly", "data.table", "haven", "tidyverse")
new.packages <-
list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
## use built-in dataset
data(mtcars)
require(tidyverse)
require(data.table)
(100, 0, 1)
values <- runif(100, 0, 1)
ifelse(values > mean(values), print(paste(values, "is more than average")),
print(paste(values, " is less than average")))
mean_v <-  mean(values)
mean_v
values[1]
ifelse(values[1] > mean(values[1]), print(paste(values[1], "is more than average")),
print(paste(values[1], " is less than average")))
if(values[1] > mean_v)
print(paste0(values[1], " is less than average"))))
print(paste(values[1], " is less than average")))
if(values[1] > mean_v)
print(paste0(values[1], " is less than average"))
if(values[1] < mean_v)
print(paste0(values[1], " is less than average"))
if(values[1] < mean_v)
print(paste0(values[1], " is less than average"))
if(values[1] < mean_v)
print(paste0(values[1], " is less than average"))
ifelse(values[1] < mean_v) print("YES"), print("NO"))
ifelse(values[1] < mean_v, print("YES"), print("NO"))
for (i in 1:100) {
val <- (i / sqrt(i))^i / 10
print(val)
}
set.seed(123)
mydata <- data.frame(x1 = seq(1, 20, by = 2),
x2 = sample(100:200, 10, FALSE),
x3 = LETTERS[1:10]) %>% setDT
mydata
sample(100:200, 10, FALSE)
set.seed(123)
sample(100:200, 10, FALSE)
mydata <- data.frame(x1 = seq(1, 20, by = 2),
x2 = sample(100:200, 10, FALSE),
x3 = LETTERS[1:10]) %>% setDT
class(mydata)
mydata[, x4 := ifelse(x2 > 150, 1, 0)]
mydata
columns(table4a)
table4a_copy
table4a_copy <- table4a
table4a_copy
class(table4a_copy)
table4a_copy <-
melt(table4a_copy,
id.vars = "country",
variable.name = "year",
value.name = "cases")
table4a_copy
table4a
table4a %>%
pivot_longer(c(`1999`, `2000`),
names_to = "year",
values_to = "cases")
table4a
require(tidyverse)
range(example.data$mpg)
example.data <- mtcars
range(example.data$mpg)
(example.data$mpg - min(example.data$mpg)) / (max(example.data$mpg) - min(example.data$mpg))
mtcars %>%
mutate(mpg.std = mpg - min(mpg) / (max(mpg)-min(mpg)))
cars <- mtcars %>%
mutate(mpg.std = mpg - min(mpg) / (max(mpg)-min(mpg)))
ar.std <- function(var) {
max_var <- max(var)
min_var <- min(var)
std.var <- var - min_var / (max_var - min_var)
return(std.var)
}
var.std <- function(var) {
max_var = max(var)
min_var = min(var)
std.var = var - min_var / (max_var - min_var)
return(std.var)
}
var.std(c(0,1,0.5,0.5,2))
var.std <- function(var) {
max_var <-  max(var)
min_var <-  min(var)
std.var <-  (var - min_var) / (max_var - min_var)
return(std.var)
}
var.std(c(0,1,0.5,0.5,2))
mtcars %>%
mutate(mpg.std = var.std(mpg),
cyl.std = var.std(cyl)
disp.std = var.std(disp))
mtcars %>%
mutate(mpg.std = var.std(mpg),
cyl.std = var.std(cyl),
disp.std = var.std(disp))
## install nycflights13 if not installed
if(!("nycflights13" %in% installed.packages()[,"Package"])) install.packages("nycflights13", dependencies = T)
library(nycflights13)
install.packages("dplyr")
example.data2 <- dplyr::select(flights,
year:day,
ends_with("delay"),
distance,
air_time,
carrier)
example.data2
xample.data2 %>%
mutate(air_time.std = var.std(air_time))
example.data2 %>%
mutate(air_time.std = var.std(air_time))
## custom function to covert values
#the flight dataset
example.data2 %>%
mutate(air_time.std = var.std(air_time)) %>%
View
var.std <- function(var, remove.na = TRUE) {
max_var <-  max(var, na.rm = remove.na)
min_var <-  min(var, na.rm = remove.na)
std.var <-  (var - min_var) / (max_var - min_var)
return(std.var)
}
example.data2 %>%
mutate(air_time.std = var.std(air_time)) %>%
View
test[!(is.na(test))]
test <- c(1,2,NA)
valid_value <- test[!(is.na(test))]
valid_value
variance <- function(var, remove.na = TRUE) {
mean_var <- mean(var, na.rm = remove.na)
n <- length(var[!(is.na(var))])
variance <-  sum((var[!(is.na(var))] - mean_var)^2) / (n-1)
}
variance(test)
variance(test)
variance <- function(var, remove.na = TRUE) {
var <- var[!(is.na(var))]
mean_var <- mean(var, na.rm = remove.na)
n <- length(var)
variance <-  sum((var - mean_var)^2) / (n-1)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
clientId <- "7Xld6GXWM7Dq1CakRAlP"
clientSecret <- "zM6pIWQbBH"
## load packages
library(tidyverse)
library(rtimes)
## Package "rtimes" Development version from GitHub
devtools::install_github("ropengov/rtimes")
search_term <- URLencode("query=오물풍선") ## you can change the query term for something else
search_term
naver_search <- paste0("https://openapi.naver.com/v1/search/news.json?",
search_term, "&display=50&start=1&sort=date")
naver_search
naver_results <- httr::GET(naver_search,
add_headers("X-Naver-Client-Id" = clientId,
"X-Naver-Client-Secret" = clientSecret))
naver_search
naver_results <- httr::GET(naver_search,
add_headers("X-Naver-Client-Id" = clientId,
"X-Naver-Client-Secret" = clientSecret))
library(httr)
library(jsonlite)
url <- "https://openapi.naver.com/v1/search/news.json?query=%EC%98%A4%EB%AC%BC%ED%92%8D%EC%84%A0&display=50&start=1&sort=date"
response <- VERB("GET", url,
add_headers("X-RapidAPI-Key" = clientId),
content_type("application/octet-stream"),
encode = 'json')
Robject <- jsonlite::fromJSON(content(response, "text"))
head(Robject$response)
naver_results <- VERB("GET", url,
add_headers("X-RapidAPI-Key" = clientId),
content_type("application/octet-stream"),
encode = 'json')
require("jsonlite")
naver_search.results <-
naver_results$content %>%
rawToChar %>%
fromJSON %>% as.data.frame
View(naver_results)
View(naver_results)
View(naver_results)
View(naver_search.results)
list.of.packages <- c("stringr", "RCurl","plyr","XML","devtools", "tidyverse",
"modeltools", 'rtimes', "qdap", "data.table")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
## Package "rtimes" Development version from GitHub
devtools::install_github("ropengov/rtimes")
## load packages
library(tidyverse)
library(rtimes)
library(RCurl)
library(XML)
library(stringr)
library(plyr)
library(qdap)
## load packages
library(tidyverse)
library(rtimes)
library(RCurl)
library(XML)
library(stringr)
library(plyr)
library(qdap)
clientId <- "7Xld6GXWM7Dq1CakRAlP"
clientSecret <- "zM6pIWQbBH"
search_term <- URLencode("query=오물풍선") ## you can change the query term for something else
search_term
naver_search <- paste0("https://openapi.naver.com/v1/search/news.json?",
search_term, "&display=50&start=1&sort=date")
naver_search
naver_results <- httr::GET(naver_search,
add_headers("X-Naver-Client-Id" = clientId,
"X-Naver-Client-Secret" = clientSecret))
require("jsonlite")
naver_search.results <-
naver_results$content %>%
rawToChar %>%
fromJSON %>% as.data.frame
View(naver_search.results)
View(naver_search.results)
naver_search.results$items.title <-
gsub("&quot;", '', naver_search.results$items.title)
naver_search.results$items.title <-
gsub("<b>", "", naver_search.results$items.title)
naver_search.results$items.title <-
gsub("</b>", "", naver_search.results$items.title)
library(qdap)
list.of.packages <- c("stringr", "RCurl","plyr","XML","devtools", "tidyverse",
"modeltools", 'rtimes', "qdap", "data.table")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
## Package "rtimes" Development version from GitHub
devtools::install_github("ropengov/rtimes")
## load packages
library(tidyverse)
library(rtimes)
library(RCurl)
library(XML)
library(stringr)
library(plyr)
library(qdap)
install packages qdap
install.packages qdap
install.packages(qdap)
install.packages("pacman")
install.packages("qdap")
base_url <- "https://openapi.naver.com/v1/search/news.json?"
search_term <- URLencode("query=데이팅") ## you can change the query term for something else
search_condition <- "&display=50&start=1&sort=date"
naver_search <- paste0(base_url, search_term, search_condition)
clientId <- "xJSkHBGQoolfzs8tHbOR"
clientSecret <- "_m2Swy5ebd"
naver_results <- httr::GET(naver_search,
add_headers("X-Naver-Client-Id" = clientId,
"X-Naver-Client-Secret" = clientSecret))
list.of.packages <- c("stringr", "RCurl","plyr","XML","devtools", "tidyverse",
"modeltools", 'rtimes', "qdap", "data.table")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
## Package "rtimes" Development version from GitHub
devtools::install_github("ropengov/rtimes")
## load packages
library(tidyverse)
library(rtimes)
library(RCurl)
library(XML)
library(stringr)
library(plyr)
install.packages("pacman")
install.packages("qdap")
require(httr)
require(jsonlite)
base_url <- "https://openapi.naver.com/v1/search/news.json?"
search_term <- URLencode("query=데이팅") ## you can change the query term for something else
search_condition <- "&display=50&start=1&sort=date"
naver_search <- paste0(base_url, search_term, search_condition)
clientId <- "xJSkHBGQoolfzs8tHbOR"
clientSecret <- "_m2Swy5ebd"
naver_results <- httr::GET(naver_search,
add_headers("X-Naver-Client-Id" = clientId,
"X-Naver-Client-Secret" = clientSecret))
# check if API is working correctly
naver_results$status_code
View(naver_results)
View(naver_search.results)
# call API by combining everything
naver_result <- httr::GET(naver_search,
add_headers("X-Naver-Client-Id" = clientId,
"X-Naver-Client-Secret" = clientSecret))
# check if API is working correctly, the result = 200, congrats!
naver_result$status_code
naver_result
View(naver_result)
View(naver_search.results)
aver_result
naver_result
api_char <- base::rawToChar(api_call$content)
api_char <- base::rawToChar(naver_result$content)
# if it finds data on the web that is dataframe, convert it to df
api_JSON <- jsonlite::fromJSON(api_char, flatten = TRUE)
View(api_JSON)
# if it finds data on the web that is dataframe, convert it to df
api_result <- jsonlite::fromJSON(api_char, flatten = TRUE)
naver_result$content
api_result$items.description <-
gsub("</b>", "", api_result$items.title)
View(naver_search.results)
naver_result <-
naver_result$content %>%
rawToChar %>%
fromJSON %>% as.data.frame
View(n)
cols(naver_result)
View(naver_result)
naver_result %>%
colnames()
naver_result %>%
colnames() %>%
copy_result <- naver_result
copy_result <- naver_result
naver_result[1]
naver_result["lastBuildDate"]
naver_result["items.title"] <- "title"
View(naver_result)
View(naver_result)
naver_result["items.title"] <- copy_result["items.title"]
View(naver_result)
df <- naver_result
list_col <- colnames(df)
list_col[-3]
list_col[-5:-9]
#naver_result["items.title"] <- copy_result["items.title"]
colnames(df) <- c(list_col[-5:-9], "title", "originallink", "link", "description", "pubDate")
colnames(df)
View(df)
?sapply
df <- df %>%
mutate(
title = gsub("&quot|<b>|<\b>", "", title),
description = gsub("&quot|<b>|<\b>", "", description)
)
View(df)
df <- df %>%
mutate(
title = gsub("&quot|<b>|</b>", "", title),
description = gsub("&quot|<b>|</b>", "", description)
)
View(df)
list.of.packages <- c("stringr", "RCurl","plyr","XML","devtools", "tidyverse",
"modeltools", 'rtimes', "qdap", "data.table")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
## Package "rtimes" Development version from GitHub
devtools::install_github("ropengov/rtimes")
## load packages
library(tidyverse)
library(rtimes)
library(RCurl)
library(XML)
library(stringr)
library(plyr)
install.packages("pacman")
install.packages("qdap")
require(httr)
require(jsonlite)
Sys.setenv(NYTIMES_API_KEY = "fiR6cISQ5OHX2bASGHhZZ13Su5nDijWL")
Sys.getenv(NYTIMES_API_KEY)
Sys.getenv("NYTIMES_API_KEY")
Sys.getenv("NYTIMES_API_KEY")
require(rtimes)
## Let's first do some basic search, with the term "Biden"
Trump.articles <- as_search(q = "Trump", begin_date = "20240101", end_date = '20241017')
Trump.articles
View(Trump.articles)
# see what is stored in the list "Trump.articles"
str(Trump.articles, 1)
View(naver_result)
View(naver_search.results)
View(naver_results)
View(api_JSON)
View(api_result)
view(Trump.articles[[3]])
dat <- Trump.articles[[3]]
dat$abstract[1]
View(Trump.articles)
Trump.articles.first.50 <- lapply(0:4, function(x) {
fraction <- as_search(q = "Trump", begin_date = "20241001", end_date = '20241017', page = x)
Sys.sleep(2)
fraction
})
Trump.articles.first.50[[3]]
str(Trump.articles.first.50, 1)
mydata <- do.call(dplyr::bind_rows,
lapply(1:5, function(x) Trump.articles.first.50[[x]]$data))
dim(mydata)
mydata$abstract[1:5]
mydata$web_url
require(RCurl)
require(XML)
require(stringr)
url <- getURL(mydata$web_url[1], .encoding = "UTF-8", .mapUnicode = T)
parsed_url <- htmlParse(url, encoding = "UTF-8")
# extract paragraph
plain.text <- xpathSApply(parsed_url, "//p", xmlValue)
plain.text <- str_replace_all(plain.text, "[\r\n]" , "") ## remove line breaks
plain.text <- str_squish(plain.text) ## remove excessive white spaces
plain.text
excluding.sentences <- c("", "Advertisement", "Supported by", "Send any friend a story",
"As a subscriber, you have 10 gift articles to give each month. Anyone can read what you share.")
plain.text <- plain.text[(!plain.text %in% excluding.sentences)]
cat(paste(plain.text[-1], collapse = " "))
plain.text
mydata <-
mydata[!(grepl("https://www.nytimes.com/video/", mydata$web_url)),]
require(parallel)
mydata$full_text <- unlist(
lapply(mydata$web_url, function(x) {
url <- getURL(x, .encoding = "UTF-8", .mapUnicode = T)
parsed_url <- htmlParse(url, encoding = "UTF-8")
plain.text <- xpathSApply(parsed_url, "//p", xmlValue) ## extract all <p>***</p>
plain.text <- str_replace_all(plain.text, "[\r\n]" , "") ## remove line breaks
plain.text <- str_squish(plain.text)
plain.text <- plain.text[(!plain.text %in% excluding.sentences)]
full_text <- paste(plain.text, collapse = " ")
full_text
})
)
## check the results by viewing the data frame
View(mydata)
View(mydata)
mydata$full_text[1]
## basic dictionary methods using Quanteda
install.packages("quanteda")
install.packages("devtools")
devtools::install_github("quanteda/quanteda.corpora")
list.of.packages <- c("stringr", "RCurl", "plyr", "tm", "SentimentAnalysis",
"tidytext", 'tibble', "readtext")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
require(quanteda, warn.conflicts = FALSE, quietly = TRUE)
install.packages("devtools")
install.packages("devtools")
?tokens
toks <- tokens(c("A corpus is a set of documents",
"This is the second document in the corpus"),
remove_punct = T)
# stem (v): remove the grammar
tokens_wordstem(toks)
